HELP=org.talend.help.tSqoopImportAllTables

JDBC_PROPERTY.NAME=JDBC Property
HADOOP_PROPERTY.NAME=Hadoop Property

LONG_NAME=Imports individual tables from an RDBMS to HDFS
EXTERNAL.NAME=Sqoop Import All Tables
TEMPFILE.NAME=Temp data directory path

COMMON_SQOOP_OPTIONS.NAME=Common arguments

CONNECTION.NAME=Connection
USERNAME.NAME=Username
PASSWORD.NAME=Password
PASSWORD_STORED_IN_FILE.NAME=The password is stored in a file
PASSWORD_FILE.NAME=File path
DRIVER_JAR.NAME=Driver JAR
DRIVER_JAR.ITEM.JAR_NAME=Jar name

PRINT_LOG.NAME=Print Log
VERBOSE.NAME=Verbose
USE_MAPPERS.NAME=Specify Number of Mappers
MAPPERS.NAME=

DIRECT.NAME=Use direct import fast path
DEFINE_DIRECT_SPLIT_SIZE.NAME=Split the input stream every N bytes
DIRECT_SPLIT_SIZE.NAME=

COMPRESS.NAME=Enable compression
DEFINE_HADOOP_CODEC.NAME=Use Hadoop codec
HADOOP_CODEC.NAME=

FILE_FORMAT.NAME=File Format
FILE_FORMAT.ITEM.textfile=textfile
FILE_FORMAT.ITEM.sequencefile=sequencefile
FILE_FORMAT.ITEM.avrofile=Avro file
FILE_FORMAT.ITEM.parquetfile=Parquet file
MYSQL_DELIMITERS.NAME=Use MySQL default Delimiters

EXCLUDE_TABLE.NAME=Exclude table
TABLE_TO_EXCLUDE.NAME=
TABLE_TO_EXCLUDE.ITEM.TABLE_NAME=Table

ADDITIONAL.NAME=Additional Arguments
ADDITIONAL_ARGUMENTS.NAME=
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT=Argument
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_VALUE=Value
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--bindir=--bindir
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--connection-manager=--connection-manager
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--create-hive-table=--create-hive-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--direct-split-size=--direct-split-size
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--driver=--driver
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--enclosed-by=--enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--escaped-by=--escaped-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--fields-terminated-by=--fields-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hadoop-home=--hadoop-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-delims-replacement=--hive-delims-replacement
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-drop-import-delims=--hive-drop-import-delims
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-home=--hive-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-import=--hive-import
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-overwrite=--hive-overwrite
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-partition-key=--hive-partition-key
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-partition-value=--hive-partition-value
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-table=--hive-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--inline-lob-limit=--inline-lob-limit
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-enclosed-by=--input-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-escaped-by=--input-escaped-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-fields-terminated-by=--input-fields-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-lines-terminated-by=--input-lines-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-optionally-enclosed-by=--input-optionally-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--jar-file=--jar-file
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--lines-terminated-by=--lines-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--optionally-enclosed-by=--optionally-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--outdir=--outdir
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--package-name=--package-name
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--warehouse-dir=--warehouse-dir

ADDITIONAL_JAVA.NAME=Additional Arguments
ADDITIONAL_JAVA.ITEM.ADDITIONAL_ARGUMENT=Argument
ADDITIONAL_JAVA.ITEM.ADDITIONAL_VALUE=Value

OUTPUT_MESSAGE.NAME=Output Message

ADDITIONAL_COMMANDLINE_ARGUMENTS.NAME=

OUTPUT_MESSAGE.NAME=Output Message

QUERY_MODE.NAME=Query

USE_QUERY.NAME=Use query
QUERY.NAME=Query

USE_SPLIT.NAME=Specify Split By
SPLIT.NAME=

MODE.NAME=Mode
USE_COMMANDLINE.NAME=Use Commandline
USE_JAVAAPI.NAME=Use Java API

VERSION.NAME=Version

TYPE_MAPPING.NAME=Type mapping
DEFINE_HIVE_MAPPING.NAME=Define Hive mapping
HIVE_TYPE_MAPPING.NAME=Hive mapping
HIVE_TYPE_MAPPING.ITEM.COLUMN_NAME=Column name
HIVE_TYPE_MAPPING.ITEM.HIVE_TYPE=Hive type

CONTROL_SQOOP_OPTIONS.NAME=Import control arguments

DISTRIBUTION.NAME=Distribution
DISTRIBUTION.ITEM.HORTONWORKS=HortonWorks
DISTRIBUTION.ITEM.CLOUDERA=Cloudera
DISTRIBUTION.ITEM.AMAZON_EMR=Amazon EMR
DISTRIBUTION.ITEM.MAPR=MapR
DISTRIBUTION.ITEM.CUSTOM=Custom - Unsupported

DB_VERSION.NAME=Hadoop version
DB_VERSION.ITEM.MAPR2=MapR 2.0.0 (Sqoop 1.4)
DB_VERSION.ITEM.MAPR212=MapR 2.1.2 (Sqoop 1.4.2)
DB_VERSION.ITEM.MAPR213=MapR 2.1.3 (Sqoop 1.4.2)
DB_VERSION.ITEM.MAPR301=MapR 3.0.1 (Sqoop 1.4.2)
DB_VERSION.ITEM.MAPR310=MapR 3.1.0
DB_VERSION.ITEM.MAPR401=MapR 4.0.1(YARN mode)
DB_VERSION.ITEM.MAPR410=MapR 4.1.0(YARN mode)
DB_VERSION.ITEM.MAPR500=MapR 5.0.0(YARN mode)
DB_VERSION.ITEM.HDP_1_2=Hortonworks Data Platform V1.2.0(Bimota)
DB_VERSION.ITEM.HDP_1_3=Hortonworks Data Platform V1.3.0(Condor)
DB_VERSION.ITEM.HDP_2_0=Hortonworks Data Platform V2.0.0(BigWheel)
DB_VERSION.ITEM.HDP_2_1=Hortonworks Data Platform V2.1.0(Baikal)
DB_VERSION.ITEM.HDP_2_2=Hortonworks Data Platform V2.2.0
DB_VERSION.ITEM.HDP_2_3=Hortonworks Data Platform V2.3.2
DB_VERSION.ITEM.Cloudera_CDH4=Cloudera CDH4.X (MR 1 mode)
DB_VERSION.ITEM.Cloudera_CDH4_YARN=Cloudera CDH4.3+(YARN mode)
DB_VERSION.ITEM.Cloudera_CDH5=Cloudera CDH5.0(YARN mode)
DB_VERSION.ITEM.Cloudera_CDH5_1_MR1=Cloudera CDH5.1(MR 1 mode)
DB_VERSION.ITEM.Cloudera_CDH5_1=Cloudera CDH5.1(YARN mode)
DB_VERSION.ITEM.Cloudera_CDH5_4=Cloudera CDH5.4(YARN mode)
DB_VERSION.ITEM.APACHE_2_4_0_EMR=Apache 2.4.0

USE_DATANODE_HOSTNAME.NAME=Use Datanode Hostname

FS_DEFAULT_NAME.NAME=NameNode URI
MAPRED_JOB_TRACKER.NAME=JobTracker Host

USE_KRB.NAME=Use kerberos authentication
NAMENODE_PRINCIPAL.NAME=Namenode principal
JOBTRACKER_PRINCIPAL.NAME=JobTracker principal
RESOURCEMANAGER_PRINCIPAL.NAME=Resource manager principal
JOBHISTORY_PRINCIPAL.NAME=Job history principal
USE_KEYTAB.NAME=Use a keytab to authenticate
PRINCIPAL.NAME=Principal
KEYTAB_PATH.NAME=Keytab
AUTHENTICATION.NAME=Authentication

CONFIGURATION.NAME=Configuration

HADOOP_ADVANCED_PROPERTIES.NAME=Hadoop Properties 
HADOOP_ADVANCED_PROPERTIES.ITEM.PROPERTY=Property
HADOOP_ADVANCED_PROPERTIES.ITEM.VALUE=Value

DISTRIBUTION.ITEM.PIVOTAL_HD=Pivotal HD
DB_VERSION.ITEM.PIVOTAL_HD_1_0_1=Pivotal HD 1.0.1
DB_VERSION.ITEM.PIVOTAL_HD_2_0=Pivotal HD 2.0
USE_YARN.NAME=Use Yarn
RESOURCE_MANAGER.NAME=Resource Manager
SET_JOBHISTORY_ADDRESS.NAME=Set jobhistory address
JOBHISTORY_ADDRESS.NAME=
CLASSPATH_SEPARATOR.NAME=Path separator in server
MAPRED_JOB_MAP_MEMORY_MB.NAME = Mapred job map memory mb

MEMORY_PARAMETERS.NAME=Job memory parameters
MAPRED_JOB_MAP_MEMORY_MB.NAME = Map (in Mb)
MAPRED_JOB_REDUCE_MEMORY_MB.NAME = Reduce (in Mb)

SET_SCHEDULER_ADDRESS.NAME=Set resourcemanager scheduler address
RESOURCEMANAGER_SCHEDULER_ADDRESS.NAME=
SET_STAGING_DIRECTORY.NAME=Set staging directory
STAGING_DIRECTORY.NAME=
SET_MEMORY.NAME=Set memory
MAPREDUCE_MAP_MEMORY_MB.NAME= Map (in Mb)
MAPREDUCE_REDUCE_MEMORY_MB.NAME= Reduce (in Mb)
YARN_APP_MAPREDUCE_AM_RESOURCE_MB.NAME= ApplicationMaster (in Mb)

HADOOP_USER.NAME=Hadoop user name

CROSS_PLATFORM_SUBMISSION.NAME=Activate the cross platform application submission

DIE_ON_ERROR.NAME=Die on error

EXIT_CODE.NAME=Exit code

USE_MAPRTICKET.NAME=Force MapR Ticket authentication
MAPRTICKET_USERNAME.NAME=Username
MAPRTICKET_PASSWORD.NAME=Password
MAPRTICKET_CLUSTER.NAME=Cluster name
MAPRTICKET_DURATION.NAME=Ticket duration (in s)
SET_MAPR_HOME_DIR.NAME=Set the MapR home directory
MAPR_HOME_DIR.NAME=
SET_HADOOP_LOGIN.NAME=Specify the hadoop login configuration
AUTHENTICATION_MAPR.NAME=Authentication MapR Ticket
HADOOP_LOGIN.NAME=

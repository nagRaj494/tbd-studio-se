HELP=org.talend.help.tSqoopImportAllTables
LONG_NAME=Imports all tables from an RDBMS to HDFS
EXTERNAL.NAME=Sqoop Import All Tables
TEMPFILE.NAME=Temp data directory path
CONNECTION.NAME=Connection
USERNAME.NAME=Username
PASSWORD.NAME=Password
PRINT_LOG.NAME=Print Log
VERBOSE.NAME=Verbose
USE_MAPPERS.NAME=Specify Number of Mappers
DIRECT.NAME=Direct
COMPRESS.NAME=Compress
FILE_FORMAT.NAME=File Format
FILE_FORMAT.ITEM.textfile=textfile
FILE_FORMAT.ITEM.sequencefile=sequencefile
MYSQL_DELIMITERS.NAME=Use MySQL default Delimiters
ADDITIONAL.NAME=Additional Arguments
OUTPUT_MESSAGE.NAME=Output Message
ADDITIONAL_JAVA.NAME=Additional Arguments
ADDITIONAL_JAVA.ITEM.ADDITIONAL_ARGUMENT=Argument
ADDITIONAL_JAVA.ITEM.ADDITIONAL_VALUE=Value
QUERY_MODE.NAME=Query
USE_QUERY.NAME=Use query
QUERY.NAME=Query
USE_SPLIT.NAME=Specify Split By
MODE.NAME=Mode
USE_COMMANDLINE.NAME=Use Commandline
USE_JAVAAPI.NAME=Use Java API
VERSION.NAME=Version
DISTRIBUTION.NAME=Distribution
DISTRIBUTION.ITEM.HORTONWORKS=HortonWorks
DISTRIBUTION.ITEM.CLOUDERA=Cloudera
DISTRIBUTION.ITEM.MAPR=MapR
DB_VERSION.NAME=Hadoop version
DB_VERSION.ITEM.MapR2=MapR 2.0.0
DB_VERSION.ITEM.HDP_1_2=Hortonworks Data Platform V1.2.0(Bimota)
DB_VERSION.ITEM.Cloudera_CDH4=Cloudera CDH4.X (MR 1 mode)
FS_DEFAULT_NAME.NAME=NameNode URI
MAPRED_JOB_TRACKER.NAME=JobTracker Host
CONFIGURATION.NAME=Configuration
DB_VERSION.ITEM.MAPR212=MapR 2.1.2 (Sqoop 1.4.2)
DISTRIBUTION.ITEM.CUSTOM=Custom - Unsupported
DB_VERSION.ITEM.HDP_1_3=Hortonworks Data Platform V1.3.0(Condor)
HADOOP_ADVANCED_PROPERTIES.NAME=Hadoop Properties
HADOOP_ADVANCED_PROPERTIES.ITEM.PROPERTY=Property
HADOOP_ADVANCED_PROPERTIES.ITEM.VALUE=Value
DB_VERSION.ITEM.MAPR213=MapR 2.1.3 (Sqoop 1.4.2)
DB_VERSION.ITEM.HDP_2_0=Hortonworks Data Platform V2.0.0(BigWheel)
USE_KRB.NAME=Use kerberos authentication
NAMENODE_PRINCIPAL.NAME=Namenode principal
JOBTRACKER_PRINCIPAL.NAME=JobTracker principal
USE_KEYTAB.NAME=Use a keytab to authenticate
PRINCIPAL.NAME=Principal
KEYTAB_PATH.NAME=Keytab
AUTHENTICATION.NAME=Authentication
DISTRIBUTION.ITEM.PIVOTAL_HD=Pivotal HD
DB_VERSION.ITEM.PIVOTAL_HD_1_0_1=Pivotal HD 1.0.1
USE_YARN.NAME=Use Yarn
RESOURCE_MANAGER.NAME=Resource Manager
CLASSPATH_SEPARATOR.NAME=Path separator in server
DB_VERSION.ITEM.MAPR301=MapR 3.0.1 (Sqoop 1.4.2)
DB_VERSION.ITEM.Cloudera_CDH4_YARN=Cloudera CDH4.3+(YARN mode)
MAPRED_JOB_MAP_MEMORY_MB.NAME=Mapred job map memory mb
MAPRED_JOB_REDUCE_MEMORY_MB.NAME=Mapred job reduce memory mb
MEMORY_PARAMETERS.NAME=Job memory parameters
SET_SCHEDULER_ADDRESS.NAME=Set resourcemanager scheduler address
SET_MEMORY.NAME=Set memory
MAPREDUCE_MAP_MEMORY_MB.NAME=Map (in Mb)
MAPREDUCE_REDUCE_MEMORY_MB.NAME=Reduce (in Mb)
YARN_APP_MAPREDUCE_AM_RESOURCE_MB.NAME=ApplicationMaster (in Mb)
HADOOP_USER.NAME=Hadoop user name
DB_VERSION.ITEM.MAPR310=MapR 3.1.0 (Sqoop 1.4.2)
DB_VERSION.ITEM.HDP_2_1=Hortonworks Data Platform V2.1.0(Baikal)
DB_VERSION.ITEM.Cloudera_CDH5=Cloudera CDH5.0(YARN mode)
RESOURCEMANAGER_PRINCIPAL.NAME=Resource manager principal
JOBHISTORY_PRINCIPAL.NAME=Job history principal
DB_VERSION.ITEM.PIVOTAL_HD_2_0=Pivotal HD 2.0
SET_STAGING_DIRECTORY.NAME=Set staging directory
CROSS_PLATFORM_SUBMISSION.NAME=Activate the cross platform application submission
SET_JOBHISTORY_ADDRESS.NAME=Set jobhistory address
JDBC_PROPERTY.NAME=JDBC Property
HADOOP_PROPERTY.NAME=Hadoop Property
COMMON_SQOOP_OPTIONS.NAME=Common arguments
PASSWORD_STORED_IN_FILE.NAME=The password is stored in a file
PASSWORD_FILE.NAME=File path
DRIVER_JAR.NAME=Driver JAR
DRIVER_JAR.ITEM.JAR_NAME=Jar name
DEFINE_DIRECT_SPLIT_SIZE.NAME=Split the input stream every N bytes
DEFINE_HADOOP_CODEC.NAME=Use Hadoop codec
FILE_FORMAT.ITEM.avrofile=Avro file
EXCLUDE_TABLE.NAME=Exclude table
TABLE_TO_EXCLUDE.ITEM.TABLE_NAME=Table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT=Argument
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_VALUE=Value
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--bindir=--bindir
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--connection-manager=--connection-manager
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--create-hive-table=--create-hive-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--direct-split-size=--direct-split-size
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--driver=--driver
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--enclosed-by=--enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--escaped-by=--escaped-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--fields-terminated-by=--fields-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hadoop-home=--hadoop-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-delims-replacement=--hive-delims-replacement
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-drop-import-delims=--hive-drop-import-delims
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-home=--hive-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-import=--hive-import
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-overwrite=--hive-overwrite
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-partition-key=--hive-partition-key
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-partition-value=--hive-partition-value
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-table=--hive-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--inline-lob-limit=--inline-lob-limit
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-enclosed-by=--input-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-escaped-by=--input-escaped-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-fields-terminated-by=--input-fields-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-lines-terminated-by=--input-lines-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-optionally-enclosed-by=--input-optionally-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--jar-file=--jar-file
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--lines-terminated-by=--lines-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--optionally-enclosed-by=--optionally-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--outdir=--outdir
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--package-name=--package-name
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--warehouse-dir=--warehouse-dir
TYPE_MAPPING.NAME=Type mapping
DEFINE_HIVE_MAPPING.NAME=Define Hive mapping
HIVE_TYPE_MAPPING.NAME=Hive mapping
HIVE_TYPE_MAPPING.ITEM.COLUMN_NAME=Column name
HIVE_TYPE_MAPPING.ITEM.HIVE_TYPE=Hive type
CONTROL_SQOOP_OPTIONS.NAME=Import control arguments
DIE_ON_ERROR.NAME=Die on error
DISTRIBUTION.ITEM.AMAZON_EMR=Amazon EMR
DB_VERSION.ITEM.MAPR401=MapR 4.0.1(YARN mode)
DB_VERSION.ITEM.Cloudera_CDH5_1_MR1=Cloudera CDH5.1(MR 1 mode)
DB_VERSION.ITEM.Cloudera_CDH5_1=Cloudera CDH5.1(YARN mode)
DB_VERSION.ITEM.APACHE_2_4_0_EMR=Apache 2.4.0
USE_DATANODE_HOSTNAME.NAME=Use Datanode Hostname
EXIT_CODE.NAME=Exit code
DB_VERSION.ITEM.HDP_2_2=Hortonworks Data Platform V2.2.0
DB_VERSION.ITEM.Cloudera_CDH5_4=Cloudera CDH5.4(YARN mode)
DB_VERSION.ITEM.MAPR410=MapR 4.1.0(YARN mode)
DB_VERSION.ITEM.MAPR500=MapR 5.0.0(YARN mode)
DB_VERSION.ITEM.HDP_2_3=Hortonworks Data Platform V2.3.2
USE_MAPRTICKET.NAME=Use MapR Ticket authentication
MAPRTICKET_USERNAME.NAME=Username
MAPRTICKET_PASSWORD.NAME=Password
MAPRTICKET_CLUSTER.NAME=Cluster name
MAPRTICKET_DURATION.NAME=Ticket duration (in s)
SET_MAPR_HOME_DIR.NAME=Set the MapR home directory
SET_HADOOP_LOGIN.NAME=Specify the hadoop login configuration
AUTHENTICATION_MAPR.NAME=Authentication MapR Ticket
